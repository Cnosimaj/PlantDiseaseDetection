# -*- coding: utf-8 -*-
"""DiseaseDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y_1IyDa3YS4MdnI-_KgLLeBOVU5fb1f1
"""


import torch
torch.__version__

import random
random.seed(0)

import numpy as np
np.random.seed(0)

import tensorflow as tf
tf.random.set_seed(0)

import os
import json
from zipfile import ZipFile
from PIL import Image

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

"""TensorFow Version"""

print("Version: ",tf.__version__)

pip install kaggle

kaggle_credentials = json.load(open("kaggle.json"))

os.environ['KAGGLE_USERNAME'] = kaggle_credentials["username"]
os.environ['KAGGLE_KEY'] = kaggle_credentials["key"]

"""Downloads Plant Village Dataset"""

kaggle datasets download -d abdallahalidev/plantvillage-dataset

ls

with ZipFile('plantvillage-dataset.zip', 'r') as zip_ref:
   zip_ref.extractall()

print(os.listdir("plantvillage dataset"))

print(len(os.listdir("plantvillage dataset/segmented")))
print(os.listdir("plantvillage dataset/segmented")[:5])

print(len(os.listdir("plantvillage dataset/color")))
print(os.listdir("plantvillage dataset/color")[:5])

print(len(os.listdir("plantvillage dataset/grayscale")))
print(os.listdir("plantvillage dataset/grayscale")[:5])

"""Dataset"""

print(len(os.listdir("plantvillage dataset/color/Grape___healthy")))
print(os.listdir("plantvillage dataset/color/Grape___healthy")[:5])

base_dir = 'plantvillage dataset/color'

"""Visualize the Data"""

image_path = '/content/plantvillage dataset/color/Strawberry___healthy/00166615-5e7b-4318-8957-5e50df335ee8___RS_HL 1785.JPG'

img = mpimg.imread(image_path)
prediction = predict_image_class(model, image_path, class_indices)
print(img.shape,'Class:',os.path.basename(os.path.dirname(image_path)))

plt.imshow(img)
plt.axis('on')
plt.show()

image_path = '/content/plantvillage dataset/color/Strawberry___healthy/00166615-5e7b-4318-8957-5e50df335ee8___RS_HL 1785.JPG'

img = mpimg.imread(image_path)

print(img)

img_size = 224
batch_size = 32

data_gen = ImageDataGenerator(
    rescale=1/255,
    validation_split=0.2
)

train_generator = data_gen.flow_from_directory(
    directory=base_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = data_gen.flow_from_directory(
    directory=base_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(train_generator.num_classes, activation='softmax')
])

model.summary()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

"""Train Model"""

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=5,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size
)

"""Model Evaluation"""

print("Evaluating model...")
val_loss, val_acc = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)
print(f"Validation Acc: {val_acc * 100:.2f}%")

"""Checking Performance"""

# Training and validation accuracy
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Training and validation loss
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label = 'val_loss')
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""Predictive System"""

def load_and_preprocess_image(image_path, target_size=(224, 224)):
    img = Image.open(image_path)
    img = img.resize(target_size)
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)
    # Rescaling the image
    img_array = img_array.astype('float32') / 255.
    return img_array

def predict_image_class(model, image_path, class_indices):
    preprocessed_img = load_and_preprocess_image(image_path)
    predictions = model.predict(preprocessed_img)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    predicted_class_name = class_indices[predicted_class_index]
    return predicted_class_name

"""Random Test Samples from Dataset"""

for idx, filename in enumerate(random.sample(validation_generator.filenames, 2)):
    print("SOURCE: class: %s, file: %s" % (os.path.split(filename)[0], filename))

    image_path = os.path.join(base_dir, filename)
    img = load_and_preprocess_image(image_path)
    img = img.squeeze()

    prediction = predict_image_class(model, image_path, class_indices)
    print("PREDICTED: class: %s" % (prediction)) # Print predicted class
    plt.imshow(img)
    plt.axis('off')
    plt.show()

class_indices = {v: k for k, v in train_generator.class_indices.items()}

class_indices

"""Saving as a json file"""

json.dump(class_indices, open("class_indices.json", "w"))

#image_path = '/content/test_apple_scab.jpg'
#image_path = '/content/test_grape_black_rot.jpg'
#image_path = '/content/test_peach_healthy.jpg'
predicted_class_name = predict_image_class(model, image_path, class_indices)
# Output

print("Predicted class: ", {predicted_class_name})
