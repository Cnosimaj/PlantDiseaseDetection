# -*- coding: utf-8 -*-
"""DiseaseDetectionOG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iERaGXlMc15Z_7w8kbRiWPbYW_eAarat
"""

!python --version

import torch
torch.__version__

"""Importing Libraries"""

import random
random.seed(0)

import numpy as np
np.random.seed(0)

import tensorflow as tf
tf.random.set_seed(0)

import pandas as pd
import seaborn as sns

import os
import json
from zipfile import ZipFile

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

"""TensorFow Version"""

print("Version: ",tf.__version__)

!pip install kaggle

kaggle_credentials = json.load(open("kaggle.json"))

os.environ['KAGGLE_USERNAME'] = kaggle_credentials["username"]
os.environ['KAGGLE_KEY'] = kaggle_credentials["key"]

"""Downloads Plant Village Dataset"""

!kaggle datasets download -d abdallahalidev/plantvillage-dataset

!ls

with ZipFile('plantvillage-dataset.zip', 'r') as zip_ref:
   zip_ref.extractall()

print(os.listdir("plantvillage dataset"))

print(len(os.listdir("plantvillage dataset/segmented")))
print(os.listdir("plantvillage dataset/segmented")[:5])

print(len(os.listdir("plantvillage dataset/color")))
print(os.listdir("plantvillage dataset/color")[:5])

print(len(os.listdir("plantvillage dataset/grayscale")))
print(os.listdir("plantvillage dataset/grayscale")[:5])

"""Dataset"""

print(len(os.listdir("plantvillage dataset/color/Grape___healthy")))
print(os.listdir("plantvillage dataset/color/Grape___healthy")[:5])

base_dir = 'plantvillage dataset/color'

"""Visualize the Data"""

image_path = '/content/plantvillage dataset/color/Strawberry___healthy/00166615-5e7b-4318-8957-5e50df335ee8___RS_HL 1785.JPG'

img = mpimg.imread(image_path)

print(img.shape,'Class:',os.path.basename(os.path.dirname(image_path)))

plt.imshow(img)
plt.axis('on')
plt.show()

image_path = '/content/plantvillage dataset/color/Strawberry___healthy/00166615-5e7b-4318-8957-5e50df335ee8___RS_HL 1785.JPG'

img = mpimg.imread(image_path)

print(img)

img_size = 224
batch_size = 32

data_gen = ImageDataGenerator(
    rescale=1/255,
    validation_split=0.2
)

train_generator = data_gen.flow_from_directory(
    directory=base_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = data_gen.flow_from_directory(
    directory=base_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(train_generator.num_classes, activation='softmax')
])

model.summary()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

"""Train Model"""

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=10,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size
)

"""Model Evaluation"""

print("Evaluating model...")
train_loss, train_acc = model.evaluate(train_generator, steps=train_generator.samples // batch_size)
print(f"Training Acc: {train_acc * 100:.2f}%")

print("Training Loss: ",train_loss, "Training Accuracy: ",train_acc)

print("Evaluating model...")
val_loss, val_acc = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)
print(f"Validation Acc: {val_acc * 100:.2f}%")

print("Validation Loss:",val_loss, "Validation Accuracy: ",val_acc)

"""Checking Performance"""

# Training and validation accuracy
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""Predictive System"""

def load_and_preprocess_image(image_path, target_size=(224, 224)):
    img = Image.open(image_path)
    img = img.resize(target_size)
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)
    # Rescaling the image
    img_array = img_array.astype('float32') / 255.
    return img_array

def predict_image_class(model, image_path, class_indices):
    preprocessed_img = load_and_preprocess_image(image_path)
    predictions = model.predict(preprocessed_img)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    predicted_class_name = class_indices[predicted_class_index]
    return predicted_class_name

"""Random Test Samples from Dataset"""

for idx, filename in enumerate(random.sample(validation_generator.filenames, 2)):
    print("SOURCE: class: %s, file: %s"% (os.path.split(filename)[0], filename) )

    image_path = os.path.join(base_dir, filename)
    img = load_and_preprocess_image(image_path)
    img = img.squeeze()

    plt.imshow(img)
    plt.axis('on')
    plt.show()

class_indices = {v: k for k, v in train_generator.class_indices.items()}
class_indices

"""Saving as a json file"""

json.dump(class_indices, open("class_indices.json", "w"))

#image_path = '/content/test_apple_scab.jpg'
#image_path = '/content/test_grape_black_rot.jpg'
#image_path = '/content/test_peach_healthy.jpg'
predicted_class_name = predict_image_class(model, image_path, class_indices)
# Output

print("Predicted class: ", {predicted_class_name})

"""Saving Model"""

model.save("trained_model.keras", save_format='keras')

history.history

json.dump(history.history, open("history.json", "w"))

y_pred = model.predict(validation_generator)
y_pred, y_pred.shape

predicted_class = np.argmax(y_pred, axis=0)
predicted_class

true_categories = tf.one_hot(validation_generator.classes, 38)
true_categories

Y_true = validation_generator.classes
Y_true

from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(validation_generator, steps=validation_generator.samples // batch_size + 1)
y_pred_classes = np.argmax(y_pred, axis=1)

y_true = validation_generator.classes
target_names = list(validation_generator.class_indices.keys())

print(classification_report(y_true, y_pred_classes, target_names=target_names))

